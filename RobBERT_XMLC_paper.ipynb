{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62e2bf5d",
   "metadata": {},
   "source": [
    "# RobBERT-XMLC model for Explicit and Implicit skill-extraction\n",
    "\n",
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99bb95a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data and visualization\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "import boto3\n",
    "import io\n",
    "\n",
    "# Math\n",
    "import numpy as np\n",
    "\n",
    "# Time and Logging\n",
    "import time\n",
    "import logging\n",
    "# !pip3 install torch==1.9.0 torchvision==0.10.0 \n",
    "# !pip install transformers\n",
    "# BERT model (simpletransformers will install all required packages)\n",
    "# !pip install --upgrade torch\n",
    "import torch\n",
    "# !pip install simpletransformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b238babd",
   "metadata": {},
   "source": [
    "## Settings\n",
    "\n",
    "Set the following settings to conduct experiments in the report:\n",
    "\n",
    "| EXPERIMENT NR. | MAX_TOKEN_COUNT | WITH_IMPLICIT_SKILLS | EXPERIMENT | MODEL_COMPLEXITY\n",
    "| --- | --- | --- | --- | --- | \n",
    "| 1 | 512 | True | sample20000 | advanced2 |\n",
    "| 2 | 256 | True | newsample20000 | advanced2 |\n",
    "| 3 | 256 | True | newsample20000 | advanced |\n",
    "| 4 | 256 | True | newsample20000 | basic |\n",
    "| 5 | 256 | False | newsample20000 | advanced2 |\n",
    "| 6 | 256 | True | newsample20000 | advanced2Multilingual |\n",
    "| 7 | 256 | - | bhola | advanced2Multilingual |\n",
    "| 8 | 256 | - | bhola | advanced2 |\n",
    "\n",
    "The data of the Bhola paper is in : https://drive.google.com/drive/folders/1Jn_6cQ7O09SC2upt05tUuypvSlKm-ZkL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8078cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL\n",
    "MAX_TOKEN_COUNT = 256 # 512 or 256\n",
    "EPOCHS =10# bhola is 10\n",
    "BATCH_SIZE = 4\n",
    "WARMUP_PROPORTION = 0.1\n",
    "WEIGHT_DECAY = 0.01\n",
    "LEARNING_RATE = 1e-4\n",
    "MANUAL_SEED = 42\n",
    "\n",
    "TRAIN_MODEL = True # Change this to train the model (True) or only evaluate a model (False)\n",
    "WITH_IMPLICIT_SKILLS = True # Change this \n",
    "\n",
    "if WITH_IMPLICIT_SKILLS:\n",
    "    COL_SKILLS = \"totalskills\"\n",
    "    IMPLICITNESS = \"InclImplicit\"\n",
    "else:\n",
    "    COL_SKILLS = \"skills\"\n",
    "    IMPLICITNESS = \"ExclImplicit\"\n",
    "    \n",
    "if EPOCHS != 5:\n",
    "    N_EPOCHS = '_Epochs' + str(EPOCHS)\n",
    "else:\n",
    "    N_EPOCHS = ''\n",
    "\n",
    "# FILES in S3. We put our data on S3 and read it from there. If you dont watnt o use S3 remove everything related to S3\n",
    "s3 = boto3.client('s3')\n",
    "BUCKET = ''\n",
    "EXPERIMENT = 'bhola' # Change this\n",
    "\n",
    "\n",
    "MODEL_COMPLEXITY = 'advanced2' # Change this \n",
    "# MODEL_COMPLEXITY ='advanced2Multilingual'\n",
    "# MODEL_COMPLEXITY ='advanced'\n",
    "\n",
    "if EXPERIMENT == 'bhola':\n",
    "    FILE_TO_READ_TRAIN = ''# Change this to the path of the dataset https://drive.google.com/drive/folders/1Jn_6cQ7O09SC2upt05tUuypvSlKm-ZkL\n",
    "    FILE_TO_READ_VALID = ''# Change this \n",
    "    FILE_TO_READ_TEST = ''# Change this \n",
    "    IMPLICITNESS = ''\n",
    "    if MODEL_COMPLEXITY == 'advanced2Multilingual':\n",
    "        MODEL_TYPE = \"bert_xmlc\"\n",
    "        MODEL_NAME = \"bert-base-multilingual-uncased\"\n",
    "    elif MODEL_COMPLEXITY == 'advanced2':\n",
    "        MODEL_TYPE = \"bert_xmlc\"\n",
    "        MODEL_NAME = \"bert-base-uncased\"\n",
    "    else:\n",
    "        MODEL_TYPE = \"bert\"\n",
    "        MODEL_NAME = \"bert-base-uncased\"\n",
    "else:\n",
    "    FILE_TO_READ_TRAIN = '' #Change this to the path of your dataset\n",
    "    FILE_TO_READ_VALID = '' #Change this to the path of your dataset\n",
    "    FILE_TO_READ_TEST = '' #Change this to the path of your dataset\n",
    "    if MODEL_COMPLEXITY == 'advanced2Multilingual':\n",
    "        MODEL_TYPE = \"bert_xmlc\"\n",
    "        MODEL_NAME = \"bert-base-multilingual-uncased\"\n",
    "    elif MODEL_COMPLEXITY == 'advanced2':\n",
    "        MODEL_TYPE = \"roberta_xmlc\"\n",
    "        MODEL_NAME = \"pdelobelle/robbert-v2-dutch-base\"\n",
    "    elif MODEL_COMPLEXITY == 'advanced':\n",
    "        MODEL_TYPE = \"roberta_xmlc1\"\n",
    "        MODEL_NAME = \"pdelobelle/robbert-v2-dutch-base\"\n",
    "    elif MODEL_COMPLEXITY == 'basic':\n",
    "        MODEL_TYPE = \"roberta_xmlc_basic\"\n",
    "        MODEL_NAME = \"pdelobelle/robbert-v2-dutch-base\"\n",
    "    else:\n",
    "        MODEL_TYPE = \"roberta\" \n",
    "        MODEL_NAME = \"pdelobelle/robbert-v2-dutch-base\"\n",
    "    \n",
    "BEST_MODEL_DIR = 'outputs/model_' + EXPERIMENT + MODEL_COMPLEXITY + IMPLICITNESS + N_EPOCHS\n",
    "OUTPUT_RESULTS_OVERVIEW = EXPERIMENT + MODEL_COMPLEXITY + IMPLICITNESS + N_EPOCHS + '_results_overviewweights.tsv'\n",
    "OUTPUT_RESULTS = EXPERIMENT + MODEL_COMPLEXITY + IMPLICITNESS + N_EPOCHS + '_results.tsv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7816fd",
   "metadata": {},
   "source": [
    "## Adjusted Simple Transformers Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fb485f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Code copied from Simple Transformers: https://github.com/ThilinaRajapakse/simpletransformers/blob/master/simpletransformers/custom_models/models.py\n",
    "Adjusted for own use.\n",
    "'''\n",
    "\n",
    "from torch import nn\n",
    "from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss, MSELoss\n",
    "from transformers import (\n",
    "    BertModel,\n",
    "    RobertaModel\n",
    ")\n",
    "from transformers.models.bert.modeling_bert import BertPreTrainedModel\n",
    "\n",
    "from transformers.models.roberta.modeling_roberta import (\n",
    "    ROBERTA_PRETRAINED_MODEL_ARCHIVE_LIST,\n",
    "    RobertaClassificationHead,\n",
    "    RobertaConfig,\n",
    "    RobertaModel,\n",
    ")\n",
    "\n",
    "import os\n",
    "import random\n",
    "import warnings\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "from transformers import (\n",
    "    WEIGHTS_NAME,\n",
    "    BertConfig,\n",
    "    BertTokenizer,\n",
    "    RobertaConfig,\n",
    "    RobertaTokenizer,\n",
    ")\n",
    "\n",
    "from simpletransformers.classification import ClassificationModel\n",
    "from simpletransformers.config.global_args import global_args\n",
    "from simpletransformers.config.model_args import MultiLabelClassificationArgs\n",
    "from simpletransformers.config.utils import sweep_config_to_sweep_values\n",
    "from simpletransformers.custom_models.models import (\n",
    "    BertForMultiLabelSequenceClassification,\n",
    "    RobertaForMultiLabelSequenceClassification\n",
    ")\n",
    "\n",
    "# 2-LAYERED BERT-XMLC\n",
    "class BertForMultiLabelSequenceClassificationXMLC(BertPreTrainedModel):\n",
    "    \"\"\"\n",
    "    Bert model adapted for multi-label sequence classification\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config, pos_weight=None):\n",
    "        super(BertForMultiLabelSequenceClassificationXMLC, self).__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        self.pos_weight = pos_weight\n",
    "        \n",
    "        self.bert = BertModel(config)\n",
    "#         self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "#         self.classifier = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "#         self.classifier_1 = nn.Linear(config.hidden_size, config.num_labels)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.classifier = nn.Linear(768, 2000)\n",
    "        self.classifier_1 = nn.Linear(2000, config.num_labels)\n",
    "#         self.relu = nn.GELU()\n",
    "#        self.init_weights()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        position_ids=None,\n",
    "        head_mask=None,\n",
    "        labels=None,\n",
    "    ):\n",
    "        outputs = self.bert(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "        )\n",
    "        \n",
    "        pooled_output = outputs[1]\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "        logits = self.relu(logits)\n",
    "        logits = self.classifier_1(logits)\n",
    "\n",
    "        outputs = (logits,) + outputs[2:]  # add hidden states and attention if they are here\n",
    "\n",
    "        if labels is not None:\n",
    "            loss_fct = BCEWithLogitsLoss(pos_weight=self.pos_weight)\n",
    "            labels = labels.float()\n",
    "            loss = loss_fct(\n",
    "                logits.view(-1, self.num_labels), labels.view(-1, self.num_labels)\n",
    "            )\n",
    "            outputs = (loss,) + outputs\n",
    "\n",
    "        return outputs  # (loss), logits, (hidden_states), (attentions)\n",
    "    \n",
    "    def unfreeze(self,start_layer,end_layer):\n",
    "        def children(m):\n",
    "            return m if isinstance(m, (list, tuple)) else list(m.children())\n",
    "        def set_trainable_attr(m, b):\n",
    "            m.trainable = b\n",
    "            for p in m.parameters():\n",
    "                p.requires_grad = b\n",
    "        def apply_leaf(m, f):\n",
    "            c = children(m)\n",
    "            if isinstance(m, nn.Module):\n",
    "                f(m)\n",
    "            if len(c) > 0:\n",
    "                for l in c:\n",
    "                    apply_leaf(l, f)\n",
    "        def set_trainable(l, b):\n",
    "            apply_leaf(l, lambda m: set_trainable_attr(m, b))\n",
    "\n",
    "        # You can unfreeze the last layer of bert by calling set_trainable(model.bert.encoder.layer[23], True)\n",
    "        set_trainable(self.bert, False)\n",
    "        for i in range(start_layer, end_layer+1):\n",
    "            set_trainable(self.bert.encoder.layer[i], True)\n",
    "\n",
    "# 2-LAYERED ROBBERT-XMLC\n",
    "\n",
    "class RobertaForMultiLabelSequenceClassificationXMLC(BertPreTrainedModel):\n",
    "    \"\"\"\n",
    "    Roberta model adapted for multi-label sequence classification\n",
    "    \"\"\"\n",
    "\n",
    "    config_class = RobertaConfig\n",
    "    pretrained_model_archive_map = ROBERTA_PRETRAINED_MODEL_ARCHIVE_LIST\n",
    "    base_model_prefix = \"roberta\"\n",
    "\n",
    "    def __init__(self, config, pos_weight=None):\n",
    "        super(RobertaForMultiLabelSequenceClassificationXMLC, self).__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        self.pos_weight = pos_weight\n",
    "\n",
    "        self.roberta = RobertaModel(config)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.classifier = nn.Linear(768, 2000)\n",
    "        self.classifier_1 = nn.Linear(2000, config.num_labels)\n",
    "#         self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "#         self.classifier = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "#         self.classifier_1 = nn.Linear(config.hidden_size, config.num_labels)\n",
    "#         self.relu = nn.GELU()\n",
    "#         self.init_weights()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(\n",
    "            self,\n",
    "            input_ids,\n",
    "            attention_mask=None,\n",
    "            token_type_ids=None,\n",
    "            position_ids=None,\n",
    "            head_mask=None,\n",
    "            labels=None,\n",
    "        ):\n",
    "\n",
    "        outputs = self.roberta(input_ids, token_type_ids=token_type_ids,attention_mask=attention_mask, head_mask=head_mask)\n",
    "        pooled_output = outputs[1]\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "        logits = self.relu(logits)\n",
    "        logits = self.classifier_1(logits)\n",
    "\n",
    "        outputs = (logits,) + outputs[2:]\n",
    "        if labels is not None:\n",
    "            loss_fct = BCEWithLogitsLoss(pos_weight=self.pos_weight)\n",
    "            labels = labels.float()\n",
    "            loss = loss_fct(\n",
    "                logits.view(-1, self.num_labels), labels.view(-1, self.num_labels)\n",
    "            )\n",
    "            outputs = (loss,) + outputs\n",
    "\n",
    "        return outputs\n",
    "\n",
    "\n",
    "    def unfreeze(self,start_layer,end_layer):\n",
    "        def children(m):\n",
    "            return m if isinstance(m, (list, tuple)) else list(m.children())\n",
    "        def set_trainable_attr(m, b):\n",
    "            m.trainable = b\n",
    "            for p in m.parameters():\n",
    "                p.requires_grad = b\n",
    "        def apply_leaf(m, f):\n",
    "            c = children(m)\n",
    "            if isinstance(m, nn.Module):\n",
    "                f(m)\n",
    "            if len(c) > 0:\n",
    "                for l in c:\n",
    "                    apply_leaf(l, f)\n",
    "        def set_trainable(l, b):\n",
    "            apply_leaf(l, lambda m: set_trainable_attr(m, b))\n",
    "\n",
    "        # You can unfreeze the last layer of bert by calling set_trainable(model.bert.encoder.layer[23], True)\n",
    "        set_trainable(self.bert, False)\n",
    "        for i in range(start_layer, end_layer+1):\n",
    "            set_trainable(self.bert.encoder.layer[i], True)\n",
    "            \n",
    "# 1-LAYERED ROBBERT-XMLC\n",
    "\n",
    "class RobertaForMultiLabelSequenceClassificationXMLC1(BertPreTrainedModel):\n",
    "    \"\"\"\n",
    "    Roberta model adapted for multi-label sequence classification\n",
    "    \"\"\"\n",
    "\n",
    "    config_class = RobertaConfig\n",
    "    pretrained_model_archive_map = ROBERTA_PRETRAINED_MODEL_ARCHIVE_LIST\n",
    "    base_model_prefix = \"roberta\"\n",
    "\n",
    "    def __init__(self, config, pos_weight=None):\n",
    "        super(RobertaForMultiLabelSequenceClassificationXMLC1, self).__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        self.pos_weight = pos_weight\n",
    "\n",
    "        self.roberta = RobertaModel(config)\n",
    "#         self.dropout = nn.Dropout(0.1)\n",
    "#         self.classifier = nn.Linear(768, config.num_labels)\n",
    "        #self.classifier_1 = nn.Linear(2000, 2548)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(\n",
    "            self,\n",
    "            input_ids,\n",
    "            attention_mask=None,\n",
    "            token_type_ids=None,\n",
    "            position_ids=None,\n",
    "            head_mask=None,\n",
    "            labels=None,\n",
    "        ):\n",
    "\n",
    "        outputs = self.roberta(input_ids, token_type_ids=token_type_ids,attention_mask=attention_mask, head_mask=head_mask)\n",
    "        pooled_output = outputs[1]\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "\n",
    "        outputs = (logits,) + outputs[2:]\n",
    "        if labels is not None:\n",
    "            loss_fct = BCEWithLogitsLoss(pos_weight=self.pos_weight)\n",
    "            labels = labels.float()\n",
    "            loss = loss_fct(\n",
    "                logits.view(-1, self.num_labels), labels.view(-1, self.num_labels)\n",
    "            )\n",
    "            outputs = (loss,) + outputs\n",
    "\n",
    "        return outputs\n",
    "\n",
    "#         logits = self.classifier(pooled_output)\n",
    "\n",
    "#         if labels is not None:\n",
    "#             loss_fct = BCEWithLogitsLoss()\n",
    "#             labels = labels.float()\n",
    "#             loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1, self.num_labels))\n",
    "#             return loss\n",
    "#         else:\n",
    "#             return logits\n",
    "\n",
    "\n",
    "    def unfreeze(self,start_layer,end_layer):\n",
    "        def children(m):\n",
    "            return m if isinstance(m, (list, tuple)) else list(m.children())\n",
    "        def set_trainable_attr(m, b):\n",
    "            m.trainable = b\n",
    "            for p in m.parameters():\n",
    "                p.requires_grad = b\n",
    "        def apply_leaf(m, f):\n",
    "            c = children(m)\n",
    "            if isinstance(m, nn.Module):\n",
    "                f(m)\n",
    "            if len(c) > 0:\n",
    "                for l in c:\n",
    "                    apply_leaf(l, f)\n",
    "        def set_trainable(l, b):\n",
    "            apply_leaf(l, lambda m: set_trainable_attr(m, b))\n",
    "\n",
    "        # You can unfreeze the last layer of bert by calling set_trainable(model.bert.encoder.layer[23], True)\n",
    "        set_trainable(self.bert, False)\n",
    "        for i in range(start_layer, end_layer+1):\n",
    "            set_trainable(self.bert.encoder.layer[i], True)\n",
    "            \n",
    "# 1-LAYERED ROBBERT-XMLC without dropout\n",
    "\n",
    "class RobertaForMultiLabelSequenceClassificationXMLCBasic(BertPreTrainedModel):\n",
    "    \"\"\"\n",
    "    Roberta model adapted for multi-label sequence classification\n",
    "    \"\"\"\n",
    "\n",
    "    config_class = RobertaConfig\n",
    "    pretrained_model_archive_map = ROBERTA_PRETRAINED_MODEL_ARCHIVE_LIST\n",
    "    base_model_prefix = \"roberta\"\n",
    "\n",
    "    def __init__(self, config, pos_weight=None):\n",
    "        super(RobertaForMultiLabelSequenceClassificationXMLCBasic, self).__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        self.pos_weight = pos_weight\n",
    "\n",
    "        self.roberta = RobertaModel(config)\n",
    "        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(\n",
    "            self,\n",
    "            input_ids,\n",
    "            attention_mask=None,\n",
    "            token_type_ids=None,\n",
    "            position_ids=None,\n",
    "            head_mask=None,\n",
    "            labels=None,\n",
    "        ):\n",
    "\n",
    "        outputs = self.roberta(input_ids, token_type_ids=token_type_ids,attention_mask=attention_mask, head_mask=head_mask)\n",
    "        pooled_output = outputs[1]\n",
    "        logits = self.classifier(pooled_output)\n",
    "\n",
    "        outputs = (logits,) + outputs[2:]\n",
    "        if labels is not None:\n",
    "            loss_fct = BCEWithLogitsLoss(pos_weight=self.pos_weight)\n",
    "            labels = labels.float()\n",
    "            loss = loss_fct(\n",
    "                logits.view(-1, self.num_labels), labels.view(-1, self.num_labels)\n",
    "            )\n",
    "            outputs = (loss,) + outputs\n",
    "\n",
    "        return outputs\n",
    "\n",
    "\n",
    "    def unfreeze(self,start_layer,end_layer):\n",
    "        def children(m):\n",
    "            return m if isinstance(m, (list, tuple)) else list(m.children())\n",
    "        def set_trainable_attr(m, b):\n",
    "            m.trainable = b\n",
    "            for p in m.parameters():\n",
    "                p.requires_grad = b\n",
    "        def apply_leaf(m, f):\n",
    "            c = children(m)\n",
    "            if isinstance(m, nn.Module):\n",
    "                f(m)\n",
    "            if len(c) > 0:\n",
    "                for l in c:\n",
    "                    apply_leaf(l, f)\n",
    "        def set_trainable(l, b):\n",
    "            apply_leaf(l, lambda m: set_trainable_attr(m, b))\n",
    "\n",
    "        # You can unfreeze the last layer of bert by calling set_trainable(model.bert.encoder.layer[23], True)\n",
    "        set_trainable(self.bert, False)\n",
    "        for i in range(start_layer, end_layer+1):\n",
    "            set_trainable(self.bert.encoder.layer[i], True)\n",
    "            \n",
    "#### Modified classification model\n",
    "            \n",
    "class MultiLabelClassificationModel(ClassificationModel):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_type,\n",
    "        model_name,\n",
    "        num_labels=None,\n",
    "        pos_weight=None,\n",
    "        args=None,\n",
    "        use_cuda=True,\n",
    "        cuda_device=-1,\n",
    "        **kwargs,\n",
    "    ):\n",
    "\n",
    "        \"\"\"\n",
    "        Initializes a MultiLabelClassification model.\n",
    "        Args:\n",
    "            model_type: The type of model (bert, roberta)\n",
    "            model_name: Default Transformer model name or path to a directory containing Transformer model file (pytorch_nodel.bin).\n",
    "            num_labels (optional): The number of labels or classes in the dataset.\n",
    "            pos_weight (optional): A list of length num_labels containing the weights to assign to each label for loss calculation.\n",
    "            args (optional): Default args will be used if this parameter is not provided. If provided, it should be a dict containing the args that should be changed in the default args.\n",
    "            use_cuda (optional): Use GPU if available. Setting to False will force model to use CPU only.\n",
    "            cuda_device (optional): Specific GPU that should be used. Will use the first available GPU by default.\n",
    "            **kwargs (optional): For providing proxies, force_download, resume_download, cache_dir and other options specific to the 'from_pretrained' implementation where this will be supplied.\n",
    "        \"\"\"  # noqa: ignore flake8\"\n",
    "\n",
    "        MODEL_CLASSES = {\n",
    "            \"bert\": (\n",
    "                BertConfig,\n",
    "                BertForMultiLabelSequenceClassification,\n",
    "                BertTokenizer,\n",
    "            ),\n",
    "            \"bert_xmlc\": (\n",
    "                BertConfig,\n",
    "                BertForMultiLabelSequenceClassificationXMLC,\n",
    "                BertTokenizer,\n",
    "            ),\n",
    "            \"roberta\": (\n",
    "                RobertaConfig,\n",
    "                RobertaForMultiLabelSequenceClassification,\n",
    "                RobertaTokenizer,\n",
    "            ),\n",
    "            \"roberta_xmlc\": (\n",
    "                RobertaConfig,\n",
    "                RobertaForMultiLabelSequenceClassificationXMLC,\n",
    "                RobertaTokenizer,\n",
    "            ),\n",
    "            \"roberta_xmlc1\": (\n",
    "                RobertaConfig,\n",
    "                RobertaForMultiLabelSequenceClassificationXMLC1,\n",
    "                RobertaTokenizer,\n",
    "            ),\n",
    "            'roberta_xmlc_basic':(\n",
    "                RobertaConfig,\n",
    "                RobertaForMultiLabelSequenceClassificationXMLCBasic,\n",
    "                RobertaTokenizer,\n",
    "            ),\n",
    "        }\n",
    "\n",
    "        self.args = self._load_model_args(model_name)\n",
    "\n",
    "        if isinstance(args, dict):\n",
    "            self.args.update_from_dict(args)\n",
    "        elif isinstance(args, MultiLabelClassificationArgs):\n",
    "            self.args = args\n",
    "\n",
    "        if self.args.thread_count:\n",
    "            torch.set_num_threads(self.args.thread_count)\n",
    "\n",
    "        if \"sweep_config\" in kwargs:\n",
    "            self.is_sweeping = True\n",
    "            sweep_config = kwargs.pop(\"sweep_config\")\n",
    "            sweep_values = sweep_config_to_sweep_values(sweep_config)\n",
    "            self.args.update_from_dict(sweep_values)\n",
    "        else:\n",
    "            self.is_sweeping = False\n",
    "\n",
    "        if self.args.manual_seed:\n",
    "            random.seed(self.args.manual_seed)\n",
    "            np.random.seed(self.args.manual_seed)\n",
    "            torch.manual_seed(self.args.manual_seed)\n",
    "            if self.args.n_gpu > 0:\n",
    "                torch.cuda.manual_seed_all(self.args.manual_seed)\n",
    "\n",
    "        if not use_cuda:\n",
    "            self.args.fp16 = False\n",
    "\n",
    "        config_class, model_class, tokenizer_class = MODEL_CLASSES[model_type]\n",
    "        if num_labels:\n",
    "            self.config = config_class.from_pretrained(\n",
    "                model_name, num_labels=num_labels, **self.args.config\n",
    "            )\n",
    "            self.num_labels = num_labels\n",
    "        else:\n",
    "            self.config = config_class.from_pretrained(model_name, **self.args.config)\n",
    "            self.num_labels = self.config.num_labels\n",
    "        self.pos_weight = pos_weight\n",
    "        \n",
    "                \n",
    "        self.loss_fct = None\n",
    "\n",
    "        if use_cuda:\n",
    "            if torch.cuda.is_available():\n",
    "                if cuda_device == -1:\n",
    "                    self.device = torch.device(\"cuda\")\n",
    "                else:\n",
    "                    self.device = torch.device(f\"cuda:{cuda_device}\")\n",
    "            else:\n",
    "                raise ValueError(\n",
    "                    \"'use_cuda' set to True when cuda is unavailable.\"\n",
    "                    \" Make sure CUDA is available or set use_cuda=False.\"\n",
    "                )\n",
    "        else:\n",
    "            self.device = \"cpu\"\n",
    "\n",
    "        if not self.args.quantized_model:\n",
    "            if self.pos_weight:\n",
    "                self.model = model_class.from_pretrained(\n",
    "                    model_name,\n",
    "                    config=self.config,\n",
    "                    pos_weight=torch.Tensor(self.pos_weight).to(self.device),\n",
    "                    **kwargs,\n",
    "                )\n",
    "            else:\n",
    "                self.model = model_class.from_pretrained(\n",
    "                    model_name, config=self.config, **kwargs\n",
    "                )\n",
    "        else:\n",
    "            quantized_weights = torch.load(\n",
    "                os.path.join(model_name, \"pytorch_model.bin\")\n",
    "            )\n",
    "            if self.pos_weight:\n",
    "                self.model = model_class.from_pretrained(\n",
    "                    None,\n",
    "                    config=self.config,\n",
    "                    state_dict=quantized_weights,\n",
    "                    weight=torch.Tensor(self.pos_weight).to(self.device),\n",
    "                )\n",
    "            else:\n",
    "                self.model = model_class.from_pretrained(\n",
    "                    None, config=self.config, state_dict=quantized_weights\n",
    "                )\n",
    "\n",
    "        if self.args.dynamic_quantize:\n",
    "            self.model = torch.quantization.quantize_dynamic(\n",
    "                self.model, {torch.nn.Linear}, dtype=torch.qint8\n",
    "            )\n",
    "        if self.args.quantized_model:\n",
    "            self.model.load_state_dict(quantized_weights)\n",
    "        if self.args.dynamic_quantize:\n",
    "            self.args.quantized_model = True\n",
    "\n",
    "        self.results = {}\n",
    "\n",
    "        self.tokenizer = tokenizer_class.from_pretrained(\n",
    "            model_name, do_lower_case=self.args.do_lower_case, **kwargs\n",
    "        )\n",
    "\n",
    "        if self.args.special_tokens_list:\n",
    "            self.tokenizer.add_tokens(\n",
    "                self.args.special_tokens_list, special_tokens=True\n",
    "            )\n",
    "            self.model.resize_token_embeddings(len(self.tokenizer))\n",
    "\n",
    "        self.args.model_name = model_name\n",
    "        self.args.model_type = model_type\n",
    "\n",
    "        if self.args.wandb_project and not wandb_available:\n",
    "            warnings.warn(\n",
    "                \"wandb_project specified but wandb is not available. Wandb disabled.\"\n",
    "            )\n",
    "            self.args.wandb_project = None\n",
    "\n",
    "        self.weight = None  # Not implemented for multilabel\n",
    "        \n",
    "            ####\n",
    "#         self.model.classifier.weight.requires_grad = True \n",
    "#         self.model.classifier_1.weight.requires_grad = True\n",
    "\n",
    "    def _load_model_args(self, input_dir):\n",
    "        args = MultiLabelClassificationArgs()\n",
    "        args.load(input_dir)\n",
    "        return args\n",
    "\n",
    "    def train_model(\n",
    "        self,\n",
    "        train_df,\n",
    "        multi_label=True,\n",
    "        eval_df=None,\n",
    "        output_dir=None,\n",
    "        show_running_loss=True,\n",
    "        args=None,\n",
    "        verbose=True,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        return super().train_model(\n",
    "            train_df,\n",
    "            multi_label=multi_label,\n",
    "            eval_df=eval_df,\n",
    "            output_dir=output_dir,\n",
    "            show_running_loss=show_running_loss,\n",
    "            verbose=True,\n",
    "            args=args,\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "    def eval_model(\n",
    "        self,\n",
    "        eval_df,\n",
    "        multi_label=True,\n",
    "        output_dir=None,\n",
    "        verbose=False,\n",
    "        silent=False,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        return super().eval_model(\n",
    "            eval_df,\n",
    "            output_dir=output_dir,\n",
    "            multi_label=multi_label,\n",
    "            verbose=verbose,\n",
    "            silent=silent,\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "    def evaluate(\n",
    "        self,\n",
    "        eval_df,\n",
    "        output_dir,\n",
    "        multi_label=True,\n",
    "        prefix=\"\",\n",
    "        verbose=True,\n",
    "        silent=False,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        return super().evaluate(\n",
    "            eval_df,\n",
    "            output_dir,\n",
    "            multi_label=multi_label,\n",
    "            prefix=prefix,\n",
    "            verbose=verbose,\n",
    "            silent=silent,\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "    def load_and_cache_examples(\n",
    "        self,\n",
    "        examples,\n",
    "        evaluate=False,\n",
    "        no_cache=False,\n",
    "        multi_label=True,\n",
    "        verbose=True,\n",
    "        silent=False,\n",
    "    ):\n",
    "        return super().load_and_cache_examples(\n",
    "            examples,\n",
    "            evaluate=evaluate,\n",
    "            no_cache=no_cache,\n",
    "            multi_label=multi_label,\n",
    "            verbose=verbose,\n",
    "            silent=silent,\n",
    "        )\n",
    "\n",
    "    def compute_metrics(\n",
    "        self, preds, model_outputs, labels, eval_examples, multi_label=True, **kwargs\n",
    "    ):\n",
    "        return super().compute_metrics(\n",
    "            preds,\n",
    "            model_outputs,\n",
    "            labels,\n",
    "            eval_examples,\n",
    "            multi_label=multi_label,\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "    def predict(self, to_predict, multi_label=True):\n",
    "        return super().predict(to_predict, multi_label=multi_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f8ad0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "transformers_logger = logging.getLogger(\"transformers\")\n",
    "transformers_logger.setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6185e1f6",
   "metadata": {},
   "source": [
    "## The Dataset\n",
    "\n",
    "### Import the data from the s3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de149a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if EXPERIMENT == 'bhola':\n",
    "    # Training dataset\n",
    "    obj = s3.get_object(Bucket=BUCKET, Key=FILE_TO_READ_TRAIN)\n",
    "    train_df = pickle.loads(obj['Body'].read())\n",
    "\n",
    "    # Validation dataset\n",
    "    obj = s3.get_object(Bucket=BUCKET, Key=FILE_TO_READ_VALID)\n",
    "    valid_df = pickle.loads(obj['Body'].read())\n",
    "\n",
    "    # Test dataset\n",
    "    obj = s3.get_object(Bucket=BUCKET, Key=FILE_TO_READ_TEST)\n",
    "    test_df = pickle.loads(obj['Body'].read())\n",
    "    \n",
    "    print(len(train_df), len(valid_df), len(test_df))\n",
    "else: \n",
    "    try:\n",
    "        # Training dataset\n",
    "        obj = s3.get_object(Bucket=BUCKET, Key=FILE_TO_READ_TRAIN)\n",
    "        train_df = pd.read_csv(io.BytesIO(obj['Body'].read()))\n",
    "\n",
    "        # Validation dataset\n",
    "        obj = s3.get_object(Bucket=BUCKET, Key=FILE_TO_READ_VALID)\n",
    "        valid_df = pd.read_csv(io.BytesIO(obj['Body'].read()))\n",
    "\n",
    "        # Test dataset\n",
    "        obj = s3.get_object(Bucket=BUCKET, Key=FILE_TO_READ_TEST)\n",
    "        test_df = pd.read_csv(io.BytesIO(obj['Body'].read()))\n",
    "\n",
    "        print(train_df.shape, valid_df.shape, test_df.shape)\n",
    "    except:\n",
    "        train_df = pd.read_csv(FILE_TO_READ_TRAIN)\n",
    "        valid_df = pd.read_csv(FILE_TO_READ_VALID)\n",
    "        test_df = pd.read_csv(FILE_TO_READ_TEST)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a014463d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82333dc0",
   "metadata": {},
   "source": [
    "### Get complete dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ed6967",
   "metadata": {},
   "outputs": [],
   "source": [
    "if EXPERIMENT != 'bhola':\n",
    "    dataset_df = pd.concat([train_df, valid_df, test_df], ignore_index = True)\n",
    "    print(dataset_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607226ff",
   "metadata": {},
   "source": [
    "### Preprocess the skills and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580e8284",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### SKILLS ##### \n",
    "def clean_skills(skills):\n",
    "    skills = skills[1:-1]\n",
    "    skills = list(skills.split(\", \"))\n",
    "    return [skill[1:-1] for skill in skills]\n",
    "\n",
    "def get_skills(dataset):\n",
    "    skills_set = set()\n",
    "\n",
    "    for skills in dataset[COL_SKILLS]:\n",
    "        skills = clean_skills(skills)\n",
    "        skills_set.update(skills)\n",
    "        \n",
    "    return skills_set\n",
    "\n",
    "def skills_set_to_dict(skills_set):\n",
    "    skills_dict = {}\n",
    "    \n",
    "    for skill in list(skills_set):\n",
    "        skills_dict[skill] = 0\n",
    "        \n",
    "    return skills_dict\n",
    "\n",
    "def get_skills_dict(dataset): \n",
    "    skills_set = get_skills(dataset)\n",
    "    skills_dict = skills_set_to_dict(skills_set)\n",
    "    return skills_dict\n",
    "\n",
    "##### VACANCIES ##### \n",
    "def process_dataset_to_columns(df, skills_dict):\n",
    "    new_df_list = []\n",
    "    for i in range(len(df)):\n",
    "        # Get text\n",
    "        text = df.iloc[i][\"job_description\"]\n",
    "\n",
    "        # Get labels\n",
    "        label_skills_dict = skills_dict.copy()\n",
    "        skills = clean_skills(df.iloc[i][COL_SKILLS])\n",
    "\n",
    "        for skill in skills:\n",
    "            if skill in skills_dict.keys():\n",
    "                label_skills_dict[skill] = 1\n",
    "        labels = list(label_skills_dict.values())\n",
    "        new_df_list.append([text, labels])\n",
    "        \n",
    "    new_df = pd.DataFrame(new_df_list, columns=[\"text\", \"labels\"])\n",
    "    \n",
    "    return new_df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efeda3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SkillsExtractionDataset(total_df, train_df, val_df):\n",
    "    ''' Process the data so that it can be used by Simple Transformers\n",
    "        Input: DataFrame\n",
    "        Output: DataFrame with only text and labels columns \n",
    "    '''\n",
    "    # Get information about skills\n",
    "    skills_dict = get_skills_dict(total_df)\n",
    "    \n",
    "    ## Check if empty is in skills_dict, delete if necessary\n",
    "    if '' in skills_dict.keys():\n",
    "        skills_dict.pop('')\n",
    "        \n",
    "    num_of_labels = len(skills_dict.keys())\n",
    "    \n",
    "    # Get columns of train set\n",
    "    start_time = time.time()\n",
    "    print(f\"Start with creating the training dataset at {time.ctime()}.\")\n",
    "    train_col_df = process_dataset_to_columns(train_df, skills_dict)\n",
    "    print(f\"Creating the training dataset cost {(time.time() - start_time)/60} minutes.\")\n",
    "    \n",
    "    # Get columns of validation set\n",
    "    start_time = time.time()\n",
    "    print(f\"Start with creating the validation dataset at {time.ctime()}.\")\n",
    "    val_col_df = process_dataset_to_columns(val_df, skills_dict)\n",
    "    print(f\"Creating the validation dataset cost {(time.time() - start_time)/60} minutes.\")\n",
    "    \n",
    "    return dict(\n",
    "        num_of_labels= num_of_labels,\n",
    "        skills_dict = skills_dict,\n",
    "        train_col_df = train_col_df,\n",
    "        val_col_df = val_col_df,\n",
    "    )\n",
    "\n",
    "def data_process_bhola(dataset):\n",
    "    ''' If the experiment is with the bhola et al dataset, use this function to process the dataset. '''\n",
    "    # Separate text from labels\n",
    "    job_descriptions = [dataset[i][0] for i in range(len(dataset))]\n",
    "    skill_labels = [dataset[i][1] for i in range(len(dataset))]\n",
    "    \n",
    "    # Create dataframe\n",
    "    data = {\"text\": job_descriptions, \"labels\": skill_labels}\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    return df\n",
    "\n",
    "if EXPERIMENT == 'bhola':\n",
    "    train_col_df = data_process_bhola(train_df)\n",
    "    val_col_df = data_process_bhola(valid_df)\n",
    "    NUM_OF_LABELS = 2548\n",
    "else:\n",
    "    dataset_dict = SkillsExtractionDataset(dataset_df, train_df, valid_df)\n",
    "    print(dataset_dict.keys())\n",
    "    NUM_OF_LABELS = dataset_dict['num_of_labels']\n",
    "    train_col_df = dataset_dict['train_col_df']\n",
    "    val_col_df = dataset_dict['val_col_df']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f0fa36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d7285d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(NUM_OF_LABELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0533c39",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "\n",
    "### Arguments\n",
    "More information on the arguments can be found at https://simpletransformers.ai/docs/usage/ ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f4abe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args = MultiLabelClassificationArgs()\n",
    "model_args.train_custom_parameters_only = True\n",
    "model_args.reprocess_input_data = True\n",
    "model_args.evaluate_during_training = True\n",
    "model_args.max_seq_length = MAX_TOKEN_COUNT\n",
    "model_args.fp16 = False\n",
    "model_args.num_train_epochs = EPOCHS\n",
    "model_args.overwrite_output_dir = True\n",
    "model_args.best_model_dir = BEST_MODEL_DIR\n",
    "model_args.eval_batch_size = BATCH_SIZE\n",
    "model_args.train_batch_size = BATCH_SIZE\n",
    "model_args.manual_seed = MANUAL_SEED\n",
    "model_args.warmup_ratio = WARMUP_PROPORTION \n",
    "model_args.save_eval_checkpoints = False\n",
    "model_args.save_eval_checkpoints = False\n",
    "model_args.save_model_every_epoch = False\n",
    "\n",
    "if MODEL_COMPLEXITY == 'advanced2Multilingual':\n",
    "    model_args.do_lower_case = True\n",
    "    \n",
    "if MODEL_COMPLEXITY == 'advanced2Multilingual' or MODEL_COMPLEXITY == 'advanced2':\n",
    "    model_args.custom_parameter_groups = [\n",
    "    {\n",
    "        \"params\": [\"classifier.weight\"],\n",
    "        \"lr\": LEARNING_RATE,\n",
    "    },\n",
    "    {\n",
    "        \"params\": [\"classifier.bias\"],\n",
    "        \"lr\": LEARNING_RATE,\n",
    "        \"weight_decay\": WEIGHT_DECAY,\n",
    "    },\n",
    "    {\n",
    "        \"params\": [\"classifier_1.weight\"],\n",
    "        \"lr\": LEARNING_RATE,\n",
    "    },\n",
    "    {\n",
    "        \"params\": [\"classifier_1.bias\"],\n",
    "        \"lr\": LEARNING_RATE,\n",
    "        \"weight_decay\": WEIGHT_DECAY,\n",
    "    }\n",
    "    ]\n",
    "else:\n",
    "    model_args.custom_parameter_groups = [\n",
    "        {\n",
    "            \"params\": [\"classifier.weight\"],\n",
    "            \"lr\": LEARNING_RATE,\n",
    "        },\n",
    "        {\n",
    "            \"params\": [\"classifier.bias\"],\n",
    "            \"lr\": LEARNING_RATE,\n",
    "            \"weight_decay\": WEIGHT_DECAY,\n",
    "        }\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a04bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167502f3",
   "metadata": {},
   "source": [
    "### Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba74a06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow\n",
    "if TRAIN_MODEL:\n",
    "    # Check whether a CUDA is available\n",
    "    cuda_available = torch.cuda.is_available()\n",
    "\n",
    "    model = MultiLabelClassificationModel(\n",
    "        MODEL_TYPE,\n",
    "        MODEL_NAME,\n",
    "        num_labels=NUM_OF_LABELS,\n",
    "        use_cuda=cuda_available,\n",
    "        args=model_args\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b555ea2",
   "metadata": {},
   "source": [
    "### Training and validating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd738e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_MODEL:\n",
    "    start_time_train = time.time()\n",
    "    print(\"Start of training:\", start_time_train)\n",
    "\n",
    "    # Train the model\n",
    "    model.train_model(train_df = train_col_df, eval_df = val_col_df)\n",
    "\n",
    "    print(\"Training took\", (time.time()-start_time_train)/60, \"minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fd277b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_MODEL:\n",
    "    start_time_val = time.time()\n",
    "    print(\"Start of validation:\", start_time_val)\n",
    "\n",
    "    # Evaluate the model\n",
    "    result, model_outputs, wrong_predictions = model.eval_model(val_col_df)\n",
    "\n",
    "    print(\"Validation took\", (time.time()-start_time_val)/60, \"minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7152425b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_MODEL:\n",
    "    print(result)\n",
    "    print(model_outputs)\n",
    "    print(len(wrong_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c772cb",
   "metadata": {},
   "source": [
    "## Testing the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1ddb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model if model is not yet loaded\n",
    "if not TRAIN_MODEL:\n",
    "    model = MultiLabelClassificationModel(\n",
    "        MODEL_TYPE, \n",
    "        BEST_MODEL_DIR,\n",
    "        num_labels=NUM_OF_LABELS,\n",
    "        use_cuda=False,\n",
    "        args=model_args\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e47a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ranked_df(i, test_df):\n",
    "    # Get info from test item\n",
    "    text = test_df.iloc[i][\"job_description\"]\n",
    "    skills = test_df.iloc[i][COL_SKILLS]\n",
    "    \n",
    "    # Get the predicted labels and predicted probabilities\n",
    "    pred_labels, pred_probs = model.predict([text])\n",
    "    \n",
    "    # Turn skills from text to labels to get the true_labels    \n",
    "    skills_dict = dataset_dict['skills_dict'].copy()\n",
    "\n",
    "    skills = clean_skills(skills)\n",
    "    for skill in skills:\n",
    "        if skill in skills_dict.keys():\n",
    "            skills_dict[skill] = 1\n",
    "\n",
    "    true_labels = [v for v in skills_dict.values()]\n",
    "\n",
    "    # Get the name of each skill\n",
    "    skill_list = [s for s in skills_dict.keys()]\n",
    "    \n",
    "    # Create DataFrame for this test item\n",
    "    data = {\"true labels\": true_labels, \"pred labels\": pred_labels[0], \"pred probs\": pred_probs[0], \"skill\": skill_list}\n",
    "    test_item_df = pd.DataFrame(data) \n",
    "    ranked_test_item_df = test_item_df.sort_values(\"pred probs\", ascending=False)\n",
    "    \n",
    "    return ranked_test_item_df\n",
    "\n",
    "def get_ranked_df_bhola(i, test_df):\n",
    "    # Process dataset\n",
    "    test_col_df = data_process_bhola(test_df)\n",
    "    \n",
    "    # Get info from test item\n",
    "    text = test_col_df.iloc[i][\"text\"]\n",
    "    true_labels = test_col_df.iloc[i][\"labels\"]\n",
    "    \n",
    "    # Get the predicted labels and predicted probabilities\n",
    "    pred_labels, pred_probs = model.predict([text])\n",
    "    \n",
    "    # Create DataFrame for this test item\n",
    "    data = {\"true labels\": true_labels, \"pred labels\": pred_labels[0], \"pred probs\": pred_probs[0]}\n",
    "    test_item_df = pd.DataFrame(data) \n",
    "    ranked_test_item_df = test_item_df.sort_values(\"pred probs\", ascending=False)\n",
    "    \n",
    "    return ranked_test_item_df\n",
    "\n",
    "# Test if it worked\n",
    "if EXPERIMENT == 'bhola':\n",
    "    ranked_test_item_df = get_ranked_df_bhola(0, test_df)\n",
    "else:\n",
    "    ranked_test_item_df = get_ranked_df(5, test_df)\n",
    "    \n",
    "print(ranked_test_item_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3c6a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_retrieved_skills(M, ranked_df):\n",
    "    skills = ranked_df['skill'].head(M)\n",
    "    return skills.tolist()\n",
    "\n",
    "def get_retrieved_probs(M, ranked_df):\n",
    "    probs = ranked_df['pred probs'].head(M)\n",
    "    return probs.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aecd7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics_values(ranked_df):\n",
    "    M = [5, 10, 30, 50, 100]\n",
    "    epsilon = 1.0e-4 # (To avoid zero-division)\n",
    "    metric_dict = {}\n",
    "    \n",
    "    true_labels = ranked_df['true labels'].to_numpy()\n",
    "    pred_labels = ranked_df['pred labels'].to_numpy()\n",
    "    \n",
    "    # Get indices of true relevant skills\n",
    "    true_index = np.where(true_labels==1)[0]\n",
    "    # Get amount of relevant skills for this job description\n",
    "    true_index_len = len(true_index)\n",
    "    # Get indices of predicted relevant skills\n",
    "    pred_index = np.where(pred_labels==1)[0]\n",
    "    \n",
    "    # Calculate RR\n",
    "    rr = 0\n",
    "    for i in range(len(true_labels)):\n",
    "        if true_labels[i] == 1:\n",
    "            rr = 1/float(i+1)\n",
    "            break       \n",
    "    metric_dict['rr'] = rr\n",
    "    \n",
    "    # Calculate Recall@M and nDCG@M and get the skills\n",
    "    skills_list = []\n",
    "    probs_list=[]\n",
    "    idcg = np.sum([1.0/np.log2(x+2) for x in range(true_index_len)]) # +2 instead of +1 since the ranking starts with 0\n",
    "    for m in M:     \n",
    "        # Calculate Recall@m\n",
    "        correct = 0\n",
    "        for i in range(m):\n",
    "            if true_labels[i] == 1:\n",
    "                correct+=1\n",
    "        metric_dict[\"recall@\" + str(m)] = correct/(true_index_len+epsilon) # Epsilon to avoid zero-division\n",
    "        \n",
    "        # Calculate nDCG@m\n",
    "        dcg = 0\n",
    "        for i in range(m):\n",
    "            if true_labels[i] == 1: # Check if the skill on this position is relevant (only true labels necessary since the first m skills will be extracted non-the-less their classification)\n",
    "                dcg = dcg + 1.0/np.log2(i+2) # +2 to avoid zero-division\n",
    "        metric_dict[\"ndcg@\" + str(m)] = dcg/idcg\n",
    "        \n",
    "        # Get skills for @m\n",
    "        skills = get_retrieved_skills(m, ranked_df)\n",
    "        probs=get_retrieved_probs(m, ranked_df)\n",
    "        \n",
    "        skills_list.append(skills)\n",
    "        probs_list.append(probs)\n",
    "        \n",
    "    return metric_dict, skills_list,probs_list\n",
    "\n",
    "def get_metrics_values_bhola(ranked_df):\n",
    "    M = [5, 10, 30, 50, 100]\n",
    "    epsilon = 1.0e-4 # (To avoid zero-division)\n",
    "    metric_dict = {}\n",
    "    \n",
    "    true_labels = ranked_df['true labels'].to_numpy()\n",
    "    pred_labels = ranked_df['pred labels'].to_numpy()\n",
    "    \n",
    "    # Get indices of true relevant skills\n",
    "    true_index = np.where(true_labels==1)[0]\n",
    "    # Get amount of relevant skills for this job description\n",
    "    true_index_len = len(true_index)\n",
    "    # Get indices of predicted relevant skills\n",
    "    pred_index = np.where(pred_labels==1)[0]\n",
    "    \n",
    "    # Calculate RR\n",
    "    rr = 0\n",
    "    for i in range(len(true_labels)):\n",
    "        if true_labels[i] == 1:\n",
    "            rr = 1/float(i+1)\n",
    "            break       \n",
    "    metric_dict['rr'] = rr\n",
    "    \n",
    "    # Calculate Recall@M and nDCG@M and get the skills\n",
    "    skills_list = []\n",
    "    idcg = np.sum([1.0/np.log2(x+2) for x in range(true_index_len)]) # +2 instead of +1 since the ranking starts with 0\n",
    "    for m in M:     \n",
    "        # Calculate Recall@m\n",
    "        correct = 0\n",
    "        for i in range(m):\n",
    "            if true_labels[i] == 1:\n",
    "                correct+=1\n",
    "        metric_dict[\"recall@\" + str(m)] = correct/(true_index_len+epsilon) # Epsilon to avoid zero-division\n",
    "        \n",
    "        # Calculate nDCG@m\n",
    "        dcg = 0\n",
    "        for i in range(m):\n",
    "            if true_labels[i] == 1: # Check if the skill on this position is relevant (only true labels necessary since the first m skills will be extracted non-the-less their classification)\n",
    "                dcg = dcg + 1.0/np.log2(i+2) # +2 to avoid zero-division\n",
    "        metric_dict[\"ndcg@\" + str(m)] = dcg/idcg\n",
    "        \n",
    "    return metric_dict\n",
    "\n",
    "if EXPERIMENT == 'bhola':\n",
    "    metric_dict = get_metrics_values_bhola(ranked_test_item_df)\n",
    "    print(metric_dict)\n",
    "else:\n",
    "    metric_dict, skills_list,probs_list = get_metrics_values(get_ranked_df(5, test_df))\n",
    "    print(metric_dict)\n",
    "    print(skills_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0999328b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metric_overview(test_df):\n",
    "    # Initiate lists\n",
    "    rec5 = []\n",
    "    rec10 = []\n",
    "    rec30 = []\n",
    "    rec50 = []\n",
    "    rec100 = []\n",
    "\n",
    "    ndcg5 = []\n",
    "    ndcg10 = []\n",
    "    ndcg30 = []\n",
    "    ndcg50 = []\n",
    "    ndcg100 = []\n",
    "\n",
    "    rr = []\n",
    "    \n",
    "    skills_all_items = []\n",
    "    probs_all_items=[]\n",
    "\n",
    "    for i in range(len(test_df)):    \n",
    "        ranked_df = get_ranked_df(i, test_df)\n",
    "        metric_dict, skills_list,probs_list = get_metrics_values(ranked_df)\n",
    "\n",
    "        rec5.append(metric_dict[\"recall@5\"])\n",
    "        rec10.append(metric_dict[\"recall@10\"])\n",
    "        rec30.append(metric_dict[\"recall@30\"])\n",
    "        rec50.append(metric_dict[\"recall@50\"])\n",
    "        rec100.append(metric_dict[\"recall@100\"])\n",
    "\n",
    "        ndcg5.append(metric_dict[\"ndcg@5\"])\n",
    "        ndcg10.append(metric_dict[\"ndcg@10\"])\n",
    "        ndcg30.append(metric_dict[\"ndcg@30\"])\n",
    "        ndcg50.append(metric_dict[\"ndcg@50\"])\n",
    "        ndcg100.append(metric_dict[\"ndcg@100\"])\n",
    "\n",
    "        rr.append(metric_dict['rr'])\n",
    "        \n",
    "        skills_all_items.append(skills_list)\n",
    "        probs_all_items.append(probs_list)\n",
    "    \n",
    "    return [rec5, rec10, rec30, rec50, rec100, ndcg5, ndcg10, ndcg30, ndcg50, ndcg100, rr], skills_all_items,probs_all_items\n",
    "\n",
    "def get_metric_overview_bhola(test_df):\n",
    "    # Initiate lists\n",
    "    rec5 = []\n",
    "    rec10 = []\n",
    "    rec30 = []\n",
    "    rec50 = []\n",
    "    rec100 = []\n",
    "\n",
    "    ndcg5 = []\n",
    "    ndcg10 = []\n",
    "    ndcg30 = []\n",
    "    ndcg50 = []\n",
    "    ndcg100 = []\n",
    "    \n",
    "    rr = []\n",
    "\n",
    "    for i in range(len(test_df)):    \n",
    "        ranked_df = get_ranked_df_bhola(i, test_df)\n",
    "        metric_dict = get_metrics_values_bhola(ranked_df)\n",
    "\n",
    "        rec5.append(metric_dict[\"recall@5\"])\n",
    "        rec10.append(metric_dict[\"recall@10\"])\n",
    "        rec30.append(metric_dict[\"recall@30\"])\n",
    "        rec50.append(metric_dict[\"recall@50\"])\n",
    "        rec100.append(metric_dict[\"recall@100\"])\n",
    "\n",
    "        ndcg5.append(metric_dict[\"ndcg@5\"])\n",
    "        ndcg10.append(metric_dict[\"ndcg@10\"])\n",
    "        ndcg30.append(metric_dict[\"ndcg@30\"])\n",
    "        ndcg50.append(metric_dict[\"ndcg@50\"])\n",
    "        ndcg100.append(metric_dict[\"ndcg@100\"])\n",
    "\n",
    "        rr.append(metric_dict['rr'])\n",
    "    \n",
    "    return [rec5, rec10, rec30, rec50, rec100, ndcg5, ndcg10, ndcg30, ndcg50, ndcg100, rr]\n",
    "\n",
    "if EXPERIMENT == 'bhola':\n",
    "    metrics_overview = get_metric_overview_bhola(test_df)\n",
    "else:\n",
    "    metrics_overview, skills_all_items,probs_all_items = get_metric_overview(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c44686a",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_names_M = ['recall5', 'recall10', 'recall30', 'recall50', 'recall100', \\\n",
    "                 'ndcg5', 'ndcg10', 'ndcg30', 'ndcg50', 'ndcg100', 'rr']\n",
    "\n",
    "metric_overview_dict = {}\n",
    "metric_and_skill_per_item = {}\n",
    "\n",
    "# Do not take into account vacancies without any explicit skills\n",
    "ignore_indices = []\n",
    "\n",
    "ndcg_5 = metrics_overview[5]\n",
    "for i in range(len(ndcg_5)):\n",
    "    if np.isnan(ndcg_5[i]):\n",
    "        ignore_indices.append(i)\n",
    "        \n",
    "print(f\"The values of {len(ignore_indices)} vacancies will not be taken into account\")\n",
    "\n",
    "for i in range(len(metric_names_M)):\n",
    "    metric = metric_names_M[i]\n",
    "    values_all = metrics_overview[i]\n",
    "    \n",
    "    values = []\n",
    "    for i in range(len(values_all)):\n",
    "        if i not in ignore_indices:\n",
    "            values.append(values_all[i])\n",
    "    \n",
    "    metric_overview_dict[metric] = [np.mean(values), np.median(values), np.min(values), np.max(values)]\n",
    "    metric_and_skill_per_item[metric] = values_all\n",
    "    \n",
    "print(f\"The mean, median, min and max values per metric@m are: \\n\", metric_overview_dict)\n",
    "# Create a dataframe to easily download the overview of the results\n",
    "df_results_overview = pd.DataFrame(metric_overview_dict)\n",
    "# Download as TSV\n",
    "df_results_overview.to_csv(OUTPUT_RESULTS_OVERVIEW, sep='\\t',index=False)\n",
    "\n",
    "# Create a dataframe to easily download the results\n",
    "df_results = pd.DataFrame(metric_and_skill_per_item)\n",
    "if EXPERIMENT != 'bhola':\n",
    "    # Add skills\n",
    "    df_results[\"retrievedskills\"] = skills_all_items\n",
    "    df_results[\"probs\"] = probs_all_items\n",
    "    \n",
    "# Download as TSV\n",
    "df_results.to_csv(OUTPUT_RESULTS, sep='\\t', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
